{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db3c95",
   "metadata": {},
   "source": [
    "# Implement the pipeline for Named Entity Recognition with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee164d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was last compiled at: 2025-09-06 07:24:43\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"This notebook was last compiled at: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab375dd1",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d6160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, mode=None):\n",
    "    df = pd.read_csv(data_dir, encoding=\"ISO-8859-1\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0b53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "    Sentence #           Word  POS    Tag\n",
      "0  Sentence: 1      Thousands  NNS      O\n",
      "1          NaN             of   IN      O\n",
      "2          NaN  demonstrators  NNS      O\n",
      "3          NaN           have  VBP      O\n",
      "4          NaN        marched  VBN      O\n",
      "5          NaN        through   IN      O\n",
      "6          NaN         London  NNP  B-geo\n",
      "7          NaN             to   TO      O\n",
      "8          NaN        protest   VB      O\n",
      "9          NaN            the   DT      O\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"/mnt/e/Development/Python/NLP/NaturalLanguageProcessing/\"\n",
    "data_dir = source_dir + \"data/archive/ner_dataset.csv\"\n",
    "print(os.path.exists(data_dir))\n",
    "df = load_data(data_dir)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a01a97",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af9ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #    1000616\n",
      "Word               10\n",
      "POS                 0\n",
      "Tag                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0537d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    # Fill NaN values in \"Sentence #\"\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].ffill()\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].astype(str)\n",
    "\n",
    "    # Drop rows with missing Word\n",
    "    data = data.dropna(subset=[\"Word\"]).reset_index(drop=True)\n",
    "\n",
    "    # Strip whitespace\n",
    "    for col in [\"Word\", \"POS\", \"Tag\"]:\n",
    "        data[col] = data[col].str.strip()\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6ab55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = preprocessing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe79240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')], [('Iranian', 'B-gpe'), ('officials', 'O'), ('say', 'O'), ('they', 'O'), ('expect', 'O'), ('to', 'O'), ('get', 'O'), ('access', 'O'), ('to', 'O'), ('sealed', 'O'), ('sensitive', 'O'), ('parts', 'O'), ('of', 'O'), ('the', 'O'), ('plant', 'O'), ('Wednesday', 'B-tim'), (',', 'O'), ('after', 'O'), ('an', 'O'), ('IAEA', 'B-org'), ('surveillance', 'O'), ('system', 'O'), ('begins', 'O'), ('functioning', 'O'), ('.', 'O')], [('Helicopter', 'O'), ('gunships', 'O'), ('Saturday', 'B-tim'), ('pounded', 'O'), ('militant', 'O'), ('hideouts', 'O'), ('in', 'O'), ('the', 'O'), ('Orakzai', 'B-geo'), ('tribal', 'O'), ('region', 'O'), (',', 'O'), ('where', 'O'), ('many', 'O'), ('Taliban', 'B-org'), ('militants', 'O'), ('are', 'O'), ('believed', 'O'), ('to', 'O'), ('have', 'O'), ('fled', 'O'), ('to', 'O'), ('avoid', 'O'), ('an', 'O'), ('earlier', 'O'), ('military', 'O'), ('offensive', 'O'), ('in', 'O'), ('nearby', 'O'), ('South', 'B-geo'), ('Waziristan', 'I-geo'), ('.', 'O')], [('They', 'O'), ('left', 'O'), ('after', 'O'), ('a', 'O'), ('tense', 'O'), ('hour-long', 'O'), ('standoff', 'O'), ('with', 'O'), ('riot', 'O'), ('police', 'O'), ('.', 'O')], [('U.N.', 'B-geo'), ('relief', 'O'), ('coordinator', 'O'), ('Jan', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('Sunday', 'B-tim'), (',', 'O'), ('U.S.', 'B-geo'), (',', 'O'), ('Indonesian', 'B-gpe'), ('and', 'O'), ('Australian', 'B-gpe'), ('military', 'O'), ('helicopters', 'O'), ('are', 'O'), ('ferrying', 'O'), ('out', 'O'), ('food', 'O'), ('and', 'O'), ('supplies', 'O'), ('to', 'O'), ('remote', 'O'), ('areas', 'O'), ('of', 'O'), ('western', 'O'), ('Aceh', 'B-geo'), ('province', 'O'), ('that', 'O'), ('ground', 'O'), ('crews', 'O'), ('can', 'O'), ('not', 'O'), ('reach', 'O'), ('.', 'O')], [('Mr.', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('the', 'O'), ('latest', 'O'), ('figures', 'O'), ('show', 'O'), ('1.8', 'O'), ('million', 'O'), ('people', 'O'), ('are', 'O'), ('in', 'O'), ('need', 'O'), ('of', 'O'), ('food', 'O'), ('assistance', 'O'), ('-', 'O'), ('with', 'O'), ('the', 'O'), ('need', 'O'), ('greatest', 'O'), ('in', 'O'), ('Indonesia', 'B-tim'), (',', 'O'), ('Sri', 'B-per'), ('Lanka', 'B-gpe'), (',', 'O'), ('the', 'O'), ('Maldives', 'B-geo'), ('and', 'O'), ('India', 'B-geo'), ('.', 'O')], [('He', 'O'), ('said', 'O'), ('last', 'O'), ('week', 'O'), (\"'s\", 'O'), ('tsunami', 'O'), ('and', 'O'), ('the', 'O'), ('massive', 'O'), ('underwater', 'O'), ('earthquake', 'O'), ('that', 'O'), ('triggered', 'O'), ('it', 'O'), ('has', 'O'), ('affected', 'O'), ('millions', 'O'), ('in', 'O'), ('Asia', 'B-geo'), ('and', 'O'), ('Africa', 'B-geo'), ('.', 'O')], [('Some', 'O'), ('1,27,000', 'O'), ('people', 'O'), ('are', 'O'), ('known', 'O'), ('dead', 'O'), ('.', 'O')], [('Aid', 'O'), ('is', 'O'), ('being', 'O'), ('rushed', 'O'), ('to', 'O'), ('the', 'O'), ('region', 'O'), (',', 'O'), ('but', 'O'), ('the', 'O'), ('U.N.', 'B-geo'), ('official', 'O'), ('stressed', 'O'), ('that', 'O'), ('bottlenecks', 'O'), ('and', 'O'), ('a', 'O'), ('lack', 'O'), ('of', 'O'), ('infrastructure', 'O'), ('remain', 'O'), ('a', 'O'), ('challenge', 'O'), ('.', 'O')], [('Lebanese', 'B-gpe'), ('politicians', 'O'), ('are', 'O'), ('condemning', 'O'), ('Friday', 'B-tim'), (\"'s\", 'O'), ('bomb', 'O'), ('blast', 'O'), ('in', 'O'), ('a', 'O'), ('Christian', 'O'), ('neighborhood', 'O'), ('of', 'O'), ('Beirut', 'B-geo'), ('as', 'O'), ('an', 'O'), ('attempt', 'O'), ('to', 'O'), ('sow', 'O'), ('sectarian', 'O'), ('strife', 'O'), ('in', 'O'), ('the', 'O'), ('formerly', 'O'), ('war-torn', 'O'), ('country', 'O'), ('.', 'O')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7186/755275269.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df.groupby(\"Sentence #\").apply(\n"
     ]
    }
   ],
   "source": [
    "# Groupby follow sentence for training\n",
    "grouped = df.groupby(\"Sentence #\").apply(\n",
    "    lambda s: list(zip(s[\"Word\"], s[\"Tag\"]))\n",
    ").tolist()\n",
    "\n",
    "print(grouped[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba12d33",
   "metadata": {},
   "source": [
    "## Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b207ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary for word and tag\n",
    "words = list(df[\"Word\"].unique())\n",
    "tags = list(df[\"Tag\"].unique())\n",
    "\n",
    "# Create dictionary word2idx, with UNK and PAD\n",
    "word2idx = {w : i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "\n",
    "# Create dictionary tag2idx, with UNK and PAD\n",
    "tag2idx = {w : i + 1 for i, w in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5d087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47959, 104]) torch.Size([47959, 104])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Mapping words to index\n",
    "X = [torch.tensor([word2idx[w[0]] for w in s], dtype=torch.long) for s in grouped]\n",
    "\n",
    "# Pad\n",
    "X = pad_sequence(X, batch_first=True, padding_value=word2idx[\"PAD\"])\n",
    "\n",
    "# Mapping tags to index\n",
    "y = [torch.tensor([tag2idx[w[1]] for w in s], dtype=torch.long) for s in grouped]\n",
    "\n",
    "# Pad\n",
    "y = pad_sequence(y, batch_first=True, padding_value=tag2idx[\"PAD\"])\n",
    "\n",
    "# Select num_tags\n",
    "num_tags = len(tag2idx)\n",
    "\n",
    "print(X.shape, y.shape)  # (num_sentences, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f7bcf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     3,     4,  ...,     0,     0,     0],\n",
      "        [  126,   127,   128,  ...,     0,     0,     0],\n",
      "        [  944,   945,   365,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  890, 16293,   326,  ...,     0,     0,     0],\n",
      "        [  837,    80,  1230,  ...,     0,     0,     0],\n",
      "        [ 4488,   304,   182,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f394fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_tags = len(tag2idx)\n",
    "y_onehot = F.one_hot(y, num_classes=num_tags + 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff14c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(y_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2d47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "pad_idx = word2idx[\"PAD\"]\n",
    "\n",
    "mask = (X != pad_idx).to(torch.uint8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc8387",
   "metadata": {},
   "source": [
    "## Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adebd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "    X, y, mask, test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198c825",
   "metadata": {},
   "source": [
    "## Build model 0 - PIPELINE with CRF and BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dikhang_hcmut/miniconda3/envs/pytorch_env/bin/python\n",
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6704ca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.2\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torchcrf; print(torchcrf.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3306651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, pad_idx):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)  # fully connected to tag space\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        # x: [batch, seq_len]\n",
    "        embeds = self.embedding(x)                  # [batch, seq_len, embedding_dim]\n",
    "        lstm_out, _ = self.lstm(embeds)             # [batch, seq_len, hidden_dim]\n",
    "        emissions = self.fc(lstm_out)               # [batch, seq_len, tagset_size]\n",
    "\n",
    "        if tags is not None:  # Training -> trả loss\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:  # Inference -> decode best path\n",
    "            return self.crf.decode(emissions, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4f4564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7186/3448389725.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
      "/tmp/ipykernel_7186/3448389725.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
      "/tmp/ipykernel_7186/3448389725.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_train_t = torch.tensor(mask_train, dtype=torch.uint8)\n",
      "/tmp/ipykernel_7186/3448389725.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_t = torch.tensor(X_test, dtype=torch.long)\n",
      "/tmp/ipykernel_7186/3448389725.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
      "/tmp/ipykernel_7186/3448389725.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_test_t = torch.tensor(mask_test, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Create Data Loader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert numpy -> tensor\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "mask_train_t = torch.tensor(mask_train, dtype=torch.uint8)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.long)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "mask_test_t = torch.tensor(mask_test, dtype=torch.uint8)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t, mask_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t, mask_test_t)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a149c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)       # số nhãn\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "\n",
    "model = BiLSTM_CRF(vocab_size, tagset_size, embedding_dim, hidden_dim, pad_idx).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0/1274, Loss: 64.3719\n",
      "Epoch 1, Step 200/1274, Loss: 11.2397\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i, (X_batch, y_batch, mask_batch) in enumerate(train_loader):\n",
    "        # Đưa dữ liệu lên GPU/CPU\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        loss = model(X_batch, tags=y_batch, mask=mask_batch)\n",
    "        #Backward\n",
    "        loss.backward()\n",
    "        # Upgrade parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 200 == 0:  # báo progress mỗi 200 batch\n",
    "            print(f\"Epoch {epoch+1}, Step {i}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✅ Epoch {epoch+1}/{EPOCHS} finished, Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bf814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch, mask_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "\n",
    "        preds = model(X_batch, mask=mask_batch)\n",
    "        labels = y_batch.cpu().numpy().tolist()\n",
    "        masks = mask_batch.cpu().numpy().tolist()\n",
    "\n",
    "        # Bỏ PAD\n",
    "        for p, l, m in zip(preds, labels, masks):\n",
    "            true_l = [ll for ll, mm in zip(l, m) if mm == 1]\n",
    "            all_labels.extend(true_l)\n",
    "            all_preds.extend(p)\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=list(tag2idx.keys())))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
