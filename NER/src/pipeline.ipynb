{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db3c95",
   "metadata": {},
   "source": [
    "# Implement the pipeline for Named Entity Recognition with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee164d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was last compiled at: 2025-09-06 07:24:43\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"This notebook was last compiled at: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab375dd1",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d6160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, mode=None):\n",
    "    df = pd.read_csv(data_dir, encoding=\"ISO-8859-1\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0b53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "    Sentence #           Word  POS    Tag\n",
      "0  Sentence: 1      Thousands  NNS      O\n",
      "1          NaN             of   IN      O\n",
      "2          NaN  demonstrators  NNS      O\n",
      "3          NaN           have  VBP      O\n",
      "4          NaN        marched  VBN      O\n",
      "5          NaN        through   IN      O\n",
      "6          NaN         London  NNP  B-geo\n",
      "7          NaN             to   TO      O\n",
      "8          NaN        protest   VB      O\n",
      "9          NaN            the   DT      O\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"/mnt/e/Development/Python/NLP/NaturalLanguageProcessing/\"\n",
    "data_dir = source_dir + \"data/archive/ner_dataset.csv\"\n",
    "print(os.path.exists(data_dir))\n",
    "df = load_data(data_dir)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a01a97",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af9ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #    1000616\n",
      "Word               10\n",
      "POS                 0\n",
      "Tag                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0537d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    # Fill NaN values in \"Sentence #\"\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].ffill()\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].astype(str)\n",
    "\n",
    "    # Drop rows with missing Word\n",
    "    data = data.dropna(subset=[\"Word\"]).reset_index(drop=True)\n",
    "\n",
    "    # Strip whitespace\n",
    "    for col in [\"Word\", \"POS\", \"Tag\"]:\n",
    "        data[col] = data[col].str.strip()\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb6ab55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = preprocessing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe79240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')], [('Iranian', 'B-gpe'), ('officials', 'O'), ('say', 'O'), ('they', 'O'), ('expect', 'O'), ('to', 'O'), ('get', 'O'), ('access', 'O'), ('to', 'O'), ('sealed', 'O'), ('sensitive', 'O'), ('parts', 'O'), ('of', 'O'), ('the', 'O'), ('plant', 'O'), ('Wednesday', 'B-tim'), (',', 'O'), ('after', 'O'), ('an', 'O'), ('IAEA', 'B-org'), ('surveillance', 'O'), ('system', 'O'), ('begins', 'O'), ('functioning', 'O'), ('.', 'O')], [('Helicopter', 'O'), ('gunships', 'O'), ('Saturday', 'B-tim'), ('pounded', 'O'), ('militant', 'O'), ('hideouts', 'O'), ('in', 'O'), ('the', 'O'), ('Orakzai', 'B-geo'), ('tribal', 'O'), ('region', 'O'), (',', 'O'), ('where', 'O'), ('many', 'O'), ('Taliban', 'B-org'), ('militants', 'O'), ('are', 'O'), ('believed', 'O'), ('to', 'O'), ('have', 'O'), ('fled', 'O'), ('to', 'O'), ('avoid', 'O'), ('an', 'O'), ('earlier', 'O'), ('military', 'O'), ('offensive', 'O'), ('in', 'O'), ('nearby', 'O'), ('South', 'B-geo'), ('Waziristan', 'I-geo'), ('.', 'O')], [('They', 'O'), ('left', 'O'), ('after', 'O'), ('a', 'O'), ('tense', 'O'), ('hour-long', 'O'), ('standoff', 'O'), ('with', 'O'), ('riot', 'O'), ('police', 'O'), ('.', 'O')], [('U.N.', 'B-geo'), ('relief', 'O'), ('coordinator', 'O'), ('Jan', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('Sunday', 'B-tim'), (',', 'O'), ('U.S.', 'B-geo'), (',', 'O'), ('Indonesian', 'B-gpe'), ('and', 'O'), ('Australian', 'B-gpe'), ('military', 'O'), ('helicopters', 'O'), ('are', 'O'), ('ferrying', 'O'), ('out', 'O'), ('food', 'O'), ('and', 'O'), ('supplies', 'O'), ('to', 'O'), ('remote', 'O'), ('areas', 'O'), ('of', 'O'), ('western', 'O'), ('Aceh', 'B-geo'), ('province', 'O'), ('that', 'O'), ('ground', 'O'), ('crews', 'O'), ('can', 'O'), ('not', 'O'), ('reach', 'O'), ('.', 'O')], [('Mr.', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('the', 'O'), ('latest', 'O'), ('figures', 'O'), ('show', 'O'), ('1.8', 'O'), ('million', 'O'), ('people', 'O'), ('are', 'O'), ('in', 'O'), ('need', 'O'), ('of', 'O'), ('food', 'O'), ('assistance', 'O'), ('-', 'O'), ('with', 'O'), ('the', 'O'), ('need', 'O'), ('greatest', 'O'), ('in', 'O'), ('Indonesia', 'B-tim'), (',', 'O'), ('Sri', 'B-per'), ('Lanka', 'B-gpe'), (',', 'O'), ('the', 'O'), ('Maldives', 'B-geo'), ('and', 'O'), ('India', 'B-geo'), ('.', 'O')], [('He', 'O'), ('said', 'O'), ('last', 'O'), ('week', 'O'), (\"'s\", 'O'), ('tsunami', 'O'), ('and', 'O'), ('the', 'O'), ('massive', 'O'), ('underwater', 'O'), ('earthquake', 'O'), ('that', 'O'), ('triggered', 'O'), ('it', 'O'), ('has', 'O'), ('affected', 'O'), ('millions', 'O'), ('in', 'O'), ('Asia', 'B-geo'), ('and', 'O'), ('Africa', 'B-geo'), ('.', 'O')], [('Some', 'O'), ('1,27,000', 'O'), ('people', 'O'), ('are', 'O'), ('known', 'O'), ('dead', 'O'), ('.', 'O')], [('Aid', 'O'), ('is', 'O'), ('being', 'O'), ('rushed', 'O'), ('to', 'O'), ('the', 'O'), ('region', 'O'), (',', 'O'), ('but', 'O'), ('the', 'O'), ('U.N.', 'B-geo'), ('official', 'O'), ('stressed', 'O'), ('that', 'O'), ('bottlenecks', 'O'), ('and', 'O'), ('a', 'O'), ('lack', 'O'), ('of', 'O'), ('infrastructure', 'O'), ('remain', 'O'), ('a', 'O'), ('challenge', 'O'), ('.', 'O')], [('Lebanese', 'B-gpe'), ('politicians', 'O'), ('are', 'O'), ('condemning', 'O'), ('Friday', 'B-tim'), (\"'s\", 'O'), ('bomb', 'O'), ('blast', 'O'), ('in', 'O'), ('a', 'O'), ('Christian', 'O'), ('neighborhood', 'O'), ('of', 'O'), ('Beirut', 'B-geo'), ('as', 'O'), ('an', 'O'), ('attempt', 'O'), ('to', 'O'), ('sow', 'O'), ('sectarian', 'O'), ('strife', 'O'), ('in', 'O'), ('the', 'O'), ('formerly', 'O'), ('war-torn', 'O'), ('country', 'O'), ('.', 'O')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7186/755275269.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df.groupby(\"Sentence #\").apply(\n"
     ]
    }
   ],
   "source": [
    "# Groupby follow sentence for training\n",
    "grouped = df.groupby(\"Sentence #\").apply(\n",
    "    lambda s: list(zip(s[\"Word\"], s[\"Tag\"]))\n",
    ").tolist()\n",
    "\n",
    "print(grouped[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba12d33",
   "metadata": {},
   "source": [
    "## Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b207ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary for word and tag\n",
    "words = list(df[\"Word\"].unique())\n",
    "tags = list(df[\"Tag\"].unique())\n",
    "\n",
    "# Create dictionary word2idx, with UNK and PAD\n",
    "word2idx = {w : i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "\n",
    "# Create dictionary tag2idx, with UNK and PAD\n",
    "tag2idx = {w : i + 1 for i, w in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5d087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47959, 104]) torch.Size([47959, 104])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Mapping words to index\n",
    "X = [torch.tensor([word2idx[w[0]] for w in s], dtype=torch.long) for s in grouped]\n",
    "\n",
    "# Pad\n",
    "X = pad_sequence(X, batch_first=True, padding_value=word2idx[\"PAD\"])\n",
    "\n",
    "# Mapping tags to index\n",
    "y = [torch.tensor([tag2idx[w[1]] for w in s], dtype=torch.long) for s in grouped]\n",
    "\n",
    "# Pad\n",
    "y = pad_sequence(y, batch_first=True, padding_value=tag2idx[\"PAD\"])\n",
    "\n",
    "# Select num_tags\n",
    "num_tags = len(tag2idx)\n",
    "\n",
    "print(X.shape, y.shape)  # (num_sentences, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f7bcf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     3,     4,  ...,     0,     0,     0],\n",
      "        [  126,   127,   128,  ...,     0,     0,     0],\n",
      "        [  944,   945,   365,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  890, 16293,   326,  ...,     0,     0,     0],\n",
      "        [  837,    80,  1230,  ...,     0,     0,     0],\n",
      "        [ 4488,   304,   182,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f394fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_tags = len(tag2idx)\n",
    "y_onehot = F.one_hot(y, num_classes=num_tags + 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff14c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(y_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2d47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "pad_idx = word2idx[\"PAD\"]\n",
    "\n",
    "mask = (X != pad_idx).to(torch.uint8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc8387",
   "metadata": {},
   "source": [
    "## Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adebd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "    X, y, mask, test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198c825",
   "metadata": {},
   "source": [
    "## Build model 0 - PIPELINE with CRF and BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dikhang_hcmut/miniconda3/envs/pytorch_env/bin/python\n",
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6704ca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.2\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torchcrf; print(torchcrf.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3306651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, pad_idx):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)  # fully connected to tag space\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        # x: [batch, seq_len]\n",
    "        embeds = self.embedding(x)                  # [batch, seq_len, embedding_dim]\n",
    "        lstm_out, _ = self.lstm(embeds)             # [batch, seq_len, hidden_dim]\n",
    "        emissions = self.fc(lstm_out)               # [batch, seq_len, tagset_size]\n",
    "\n",
    "        if tags is not None:  # Training -> trả loss\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:  # Inference -> decode best path\n",
    "            return self.crf.decode(emissions, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert numpy -> tensor\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "mask_train_t = torch.tensor(mask_train, dtype=torch.uint8)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.long)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "mask_test_t = torch.tensor(mask_test, dtype=torch.uint8)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t, mask_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t, mask_test_t)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0a149c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and optimizer\n",
    "vocab_size = len(words) + 2\n",
    "tagset_size = num_tag + 1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "\n",
    "model = BiLSTM_CRF(vocab_size, tagset_size, embedding_dim, hidden_dim, pad_idx)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5f8acce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the first two dimensions of emissions and tags must match, got (32, 104) and (32, 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch, mask_batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m      8\u001b[39m     optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     loss.backward()\n\u001b[32m     11\u001b[39m     optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mBiLSTM_CRF.forward\u001b[39m\u001b[34m(self, x, tags, mask)\u001b[39m\n\u001b[32m     18\u001b[39m emissions = \u001b[38;5;28mself\u001b[39m.fc(lstm_out)               \u001b[38;5;66;03m# [batch, seq_len, tagset_size]\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Training -> trả loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     loss = -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Inference -> decode best path\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchcrf/__init__.py:90\u001b[39m, in \u001b[36mCRF.forward\u001b[39m\u001b[34m(self, emissions, tags, mask, reduction)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     65\u001b[39m         emissions: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m         reduction: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     69\u001b[39m ) -> torch.Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the conditional log likelihood of a sequence of tags given emission scores.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m        reduction is ``none``, ``()`` otherwise.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtoken_mean\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     92\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33minvalid reduction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreduction\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchcrf/__init__.py:156\u001b[39m, in \u001b[36mCRF._validate\u001b[39m\u001b[34m(self, emissions, tags, mask)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emissions.shape[:\u001b[32m2\u001b[39m] != tags.shape:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    157\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mthe first two dimensions of emissions and tags must match, \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    158\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(emissions.shape[\u001b[32m0\u001b[39m],\u001b[38;5;250m \u001b[39memissions.shape[\u001b[32m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(tags.shape[\u001b[32m0\u001b[39m],\u001b[38;5;250m \u001b[39mtags.shape[\u001b[32m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    159\u001b[39m         )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emissions.shape[:\u001b[32m2\u001b[39m] != mask.shape:\n",
      "\u001b[31mValueError\u001b[39m: the first two dimensions of emissions and tags must match, got (32, 104) and (32, 104)"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x_batch, y_batch, mask_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(x_batch, y_batch, mask_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
