{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db3c95",
   "metadata": {},
   "source": [
    "# Implement the pipeline for Named Entity Recognition with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee164d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was last compiled at: 2025-09-06 08:36:35\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"This notebook was last compiled at: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab375dd1",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, mode=None):\n",
    "    df = pd.read_csv(data_dir, encoding=\"ISO-8859-1\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "    Sentence #           Word  POS    Tag\n",
      "0  Sentence: 1      Thousands  NNS      O\n",
      "1          NaN             of   IN      O\n",
      "2          NaN  demonstrators  NNS      O\n",
      "3          NaN           have  VBP      O\n",
      "4          NaN        marched  VBN      O\n",
      "5          NaN        through   IN      O\n",
      "6          NaN         London  NNP  B-geo\n",
      "7          NaN             to   TO      O\n",
      "8          NaN        protest   VB      O\n",
      "9          NaN            the   DT      O\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"/mnt/e/Development/Python/NLP/NaturalLanguageProcessing/\"\n",
    "data_dir = source_dir + \"data/archive/ner_dataset.csv\"\n",
    "print(os.path.exists(data_dir))\n",
    "df = load_data(data_dir)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a01a97",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #    1000616\n",
      "Word               10\n",
      "POS                 0\n",
      "Tag                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0537d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    # Fill NaN values in \"Sentence #\"\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].ffill()\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].astype(str)\n",
    "\n",
    "    # Drop rows with missing Word\n",
    "    data = data.dropna(subset=[\"Word\"]).reset_index(drop=True)\n",
    "\n",
    "    # Strip whitespace\n",
    "    for col in [\"Word\", \"POS\", \"Tag\"]:\n",
    "        data[col] = data[col].str.strip()\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ab55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = preprocessing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe79240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')], [('Iranian', 'B-gpe'), ('officials', 'O'), ('say', 'O'), ('they', 'O'), ('expect', 'O'), ('to', 'O'), ('get', 'O'), ('access', 'O'), ('to', 'O'), ('sealed', 'O'), ('sensitive', 'O'), ('parts', 'O'), ('of', 'O'), ('the', 'O'), ('plant', 'O'), ('Wednesday', 'B-tim'), (',', 'O'), ('after', 'O'), ('an', 'O'), ('IAEA', 'B-org'), ('surveillance', 'O'), ('system', 'O'), ('begins', 'O'), ('functioning', 'O'), ('.', 'O')], [('Helicopter', 'O'), ('gunships', 'O'), ('Saturday', 'B-tim'), ('pounded', 'O'), ('militant', 'O'), ('hideouts', 'O'), ('in', 'O'), ('the', 'O'), ('Orakzai', 'B-geo'), ('tribal', 'O'), ('region', 'O'), (',', 'O'), ('where', 'O'), ('many', 'O'), ('Taliban', 'B-org'), ('militants', 'O'), ('are', 'O'), ('believed', 'O'), ('to', 'O'), ('have', 'O'), ('fled', 'O'), ('to', 'O'), ('avoid', 'O'), ('an', 'O'), ('earlier', 'O'), ('military', 'O'), ('offensive', 'O'), ('in', 'O'), ('nearby', 'O'), ('South', 'B-geo'), ('Waziristan', 'I-geo'), ('.', 'O')], [('They', 'O'), ('left', 'O'), ('after', 'O'), ('a', 'O'), ('tense', 'O'), ('hour-long', 'O'), ('standoff', 'O'), ('with', 'O'), ('riot', 'O'), ('police', 'O'), ('.', 'O')], [('U.N.', 'B-geo'), ('relief', 'O'), ('coordinator', 'O'), ('Jan', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('Sunday', 'B-tim'), (',', 'O'), ('U.S.', 'B-geo'), (',', 'O'), ('Indonesian', 'B-gpe'), ('and', 'O'), ('Australian', 'B-gpe'), ('military', 'O'), ('helicopters', 'O'), ('are', 'O'), ('ferrying', 'O'), ('out', 'O'), ('food', 'O'), ('and', 'O'), ('supplies', 'O'), ('to', 'O'), ('remote', 'O'), ('areas', 'O'), ('of', 'O'), ('western', 'O'), ('Aceh', 'B-geo'), ('province', 'O'), ('that', 'O'), ('ground', 'O'), ('crews', 'O'), ('can', 'O'), ('not', 'O'), ('reach', 'O'), ('.', 'O')], [('Mr.', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('the', 'O'), ('latest', 'O'), ('figures', 'O'), ('show', 'O'), ('1.8', 'O'), ('million', 'O'), ('people', 'O'), ('are', 'O'), ('in', 'O'), ('need', 'O'), ('of', 'O'), ('food', 'O'), ('assistance', 'O'), ('-', 'O'), ('with', 'O'), ('the', 'O'), ('need', 'O'), ('greatest', 'O'), ('in', 'O'), ('Indonesia', 'B-tim'), (',', 'O'), ('Sri', 'B-per'), ('Lanka', 'B-gpe'), (',', 'O'), ('the', 'O'), ('Maldives', 'B-geo'), ('and', 'O'), ('India', 'B-geo'), ('.', 'O')], [('He', 'O'), ('said', 'O'), ('last', 'O'), ('week', 'O'), (\"'s\", 'O'), ('tsunami', 'O'), ('and', 'O'), ('the', 'O'), ('massive', 'O'), ('underwater', 'O'), ('earthquake', 'O'), ('that', 'O'), ('triggered', 'O'), ('it', 'O'), ('has', 'O'), ('affected', 'O'), ('millions', 'O'), ('in', 'O'), ('Asia', 'B-geo'), ('and', 'O'), ('Africa', 'B-geo'), ('.', 'O')], [('Some', 'O'), ('1,27,000', 'O'), ('people', 'O'), ('are', 'O'), ('known', 'O'), ('dead', 'O'), ('.', 'O')], [('Aid', 'O'), ('is', 'O'), ('being', 'O'), ('rushed', 'O'), ('to', 'O'), ('the', 'O'), ('region', 'O'), (',', 'O'), ('but', 'O'), ('the', 'O'), ('U.N.', 'B-geo'), ('official', 'O'), ('stressed', 'O'), ('that', 'O'), ('bottlenecks', 'O'), ('and', 'O'), ('a', 'O'), ('lack', 'O'), ('of', 'O'), ('infrastructure', 'O'), ('remain', 'O'), ('a', 'O'), ('challenge', 'O'), ('.', 'O')], [('Lebanese', 'B-gpe'), ('politicians', 'O'), ('are', 'O'), ('condemning', 'O'), ('Friday', 'B-tim'), (\"'s\", 'O'), ('bomb', 'O'), ('blast', 'O'), ('in', 'O'), ('a', 'O'), ('Christian', 'O'), ('neighborhood', 'O'), ('of', 'O'), ('Beirut', 'B-geo'), ('as', 'O'), ('an', 'O'), ('attempt', 'O'), ('to', 'O'), ('sow', 'O'), ('sectarian', 'O'), ('strife', 'O'), ('in', 'O'), ('the', 'O'), ('formerly', 'O'), ('war-torn', 'O'), ('country', 'O'), ('.', 'O')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21928/755275269.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df.groupby(\"Sentence #\").apply(\n"
     ]
    }
   ],
   "source": [
    "# Groupby follow sentence for training\n",
    "grouped = df.groupby(\"Sentence #\").apply(\n",
    "    lambda s: list(zip(s[\"Word\"], s[\"Tag\"]))\n",
    ").tolist()\n",
    "\n",
    "print(grouped[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba12d33",
   "metadata": {},
   "source": [
    "## Encoding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b207ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word2idx size: 35179\n",
      "Tag2idx size: 18\n",
      "Tag2idx: {'O': 1, 'B-geo': 2, 'B-gpe': 3, 'B-per': 4, 'I-geo': 5, 'B-org': 6, 'I-org': 7, 'B-tim': 8, 'B-art': 9, 'I-art': 10, 'I-per': 11, 'I-gpe': 12, 'I-tim': 13, 'B-nat': 14, 'B-eve': 15, 'I-eve': 16, 'I-nat': 17, 'PAD': 0}\n"
     ]
    }
   ],
   "source": [
    "# Create vocabulary for word and tag\n",
    "words = list(df[\"Word\"].unique())\n",
    "tags = list(df[\"Tag\"].unique())\n",
    "\n",
    "# Create dictionary word2idx, with UNK and PAD\n",
    "word2idx = {w : i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "\n",
    "# Create dictionary tag2idx, with UNK and PAD\n",
    "tag2idx = {w : i + 1 for i, w in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "print(f\"\\nWord2idx size: {len(word2idx)}\")\n",
    "print(f\"Tag2idx size: {len(tag2idx)}\")\n",
    "print(f\"Tag2idx: {tag2idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47959, 104]) torch.Size([47959, 104])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Mapping words to index\n",
    "X = [torch.tensor([word2idx.get(w[0], word2idx[\"UNK\"]) for w in s], dtype=torch.long) for s in grouped]\n",
    "\n",
    "# Pad\n",
    "X = pad_sequence(X, batch_first=True, padding_value=word2idx[\"PAD\"])\n",
    "\n",
    "# Mapping tags to index\n",
    "y = [torch.tensor([tag2idx.get(w[1], tag2idx[\"PAD\"]) for w in s], dtype=torch.long) for s in grouped]\n",
    "\n",
    "# Pad\n",
    "y = pad_sequence(y, batch_first=True, padding_value=tag2idx[\"PAD\"])\n",
    "\n",
    "# Select num_tags\n",
    "num_tags = len(tag2idx)\n",
    "vocab_size = len(word2idx)\n",
    "print(X.shape, y.shape)  # (num_sentences, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bcf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     3,     4,  ...,     0,     0,     0],\n",
      "        [  126,   127,   128,  ...,     0,     0,     0],\n",
      "        [  944,   945,   365,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  890, 16293,   326,  ...,     0,     0,     0],\n",
      "        [  837,    80,  1230,  ...,     0,     0,     0],\n",
      "        [ 4488,   304,   182,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y_onehot = F.one_hot(y, num_classes=num_tags + 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14c545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 0,  ..., 0, 0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(y_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask\n",
    "pad_idx = word2idx[\"PAD\"]\n",
    "\n",
    "mask = (X != pad_idx).to(torch.uint8) \n",
    "mask_bool = (X != pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc8387",
   "metadata": {},
   "source": [
    "## Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "    X, y, mask_bool, test_size=0.15, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198c825",
   "metadata": {},
   "source": [
    "## Build model 0 - PIPELINE with CRF and BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa7858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dikhang_hcmut/miniconda3/envs/pytorch_env/bin/python\n",
      "Python 3.12.11\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704ca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.2\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torchcrf; print(torchcrf.__version__)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3306651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, pad_idx):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)  # fully connected to tag space\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        # x: [batch, seq_len]\n",
    "        embeds = self.embedding(x)                  # [batch, seq_len, embedding_dim]\n",
    "        lstm_out, _ = self.lstm(embeds)             # [batch, seq_len, hidden_dim]\n",
    "        emissions = self.fc(lstm_out)               # [batch, seq_len, tagset_size]\n",
    "\n",
    "        if tags is not None:  # Training -> trả loss\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:  # Inference -> decode best path\n",
    "            return self.crf.decode(emissions, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce4e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUG VOCABULARY ISSUE ===\n",
      "Current vocab_size: 35179\n",
      "Current word2idx length: 35179\n",
      "Max index in word2idx: 35179\n",
      "Words with index >= vocab_size: ['Bermel']\n",
      "\n",
      "=== FINDING PROBLEMATIC BATCH ===\n",
      "Found problematic batch 161\n",
      "Max index: 35179\n",
      "Problem positions: tensor([[26, 18]])\n",
      "Problem values: tensor([35179])\n"
     ]
    }
   ],
   "source": [
    "# DEBUG TRỰC TIẾP VẤN ĐỀ VOCAB\n",
    "print(\"=== DEBUG VOCABULARY ISSUE ===\")\n",
    "\n",
    "# 1. Kiểm tra vocab mapping hiện tại\n",
    "print(f\"Current vocab_size: {vocab_size}\")\n",
    "print(f\"Current word2idx length: {len(word2idx)}\")\n",
    "print(f\"Max index in word2idx: {max(word2idx.values())}\")\n",
    "\n",
    "# Tìm từ nào có index = vocab_size\n",
    "problem_words = [word for word, idx in word2idx.items() if idx >= vocab_size]\n",
    "print(f\"Words with index >= vocab_size: {problem_words}\")\n",
    "\n",
    "# 2. Tìm batch có vấn đề\n",
    "print(f\"\\n=== FINDING PROBLEMATIC BATCH ===\")\n",
    "for batch_idx, (X_batch, y_batch, mask_batch) in enumerate(train_loader):\n",
    "    max_idx = X_batch.max().item()\n",
    "    if max_idx >= vocab_size:\n",
    "        print(f\"Found problematic batch {batch_idx}\")\n",
    "        print(f\"Max index: {max_idx}\")\n",
    "        \n",
    "        # Tìm vị trí có index sai\n",
    "        problem_positions = (X_batch >= vocab_size).nonzero()\n",
    "        print(f\"Problem positions: {problem_positions[:5]}\")  # Show first 5\n",
    "        \n",
    "        # Tìm giá trị sai\n",
    "        problem_values = X_batch[X_batch >= vocab_size]\n",
    "        print(f\"Problem values: {problem_values.unique()}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21928/1196877835.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
      "/tmp/ipykernel_21928/1196877835.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
      "/tmp/ipykernel_21928/1196877835.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_train_t = torch.tensor(mask_train, dtype=torch.bool)\n",
      "/tmp/ipykernel_21928/1196877835.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_t = torch.tensor(X_test, dtype=torch.long)\n",
      "/tmp/ipykernel_21928/1196877835.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
      "/tmp/ipykernel_21928/1196877835.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_test_t = torch.tensor(mask_test, dtype=torch.bool)\n"
     ]
    }
   ],
   "source": [
    "# Create Data Loader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert numpy -> tensor\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.long)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
    "mask_train_t = torch.tensor(mask_train, dtype=torch.bool)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.long)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "mask_test_t = torch.tensor(mask_test, dtype=torch.bool)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t, mask_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t, mask_test_t)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7314e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(max(X_batch.max().item(), y_batch.max().item()))\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90142db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Clearing CUDA cache...\n",
      "🗑️ Running garbage collection...\n",
      "Creating model with:\n",
      "vocab_size: 35179\n",
      "tagset_size: 18\n",
      "pad_idx: 0\n",
      "Model created on CPU successfully\n",
      "CPU test successful, loss: 71.67552185058594\n",
      "Model moved to GPU successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dikhang_hcmut/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchcrf/__init__.py:252: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /pytorch/aten/src/ATen/native/TensorCompare.cpp:611.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1. CLEAR CUDA CACHE\n",
    "import torch, gc\n",
    "print(\"🧹 Clearing CUDA cache...\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()  # Đợi tất cả operations hoàn thành\n",
    "    \n",
    "# 2. FORCE GARBAGE COLLECTION\n",
    "print(\"🗑️ Running garbage collection...\")\n",
    "gc.collect()\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "tagset_size = len(tag2idx)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "pad_idx = word2idx[\"PAD\"]\n",
    "\n",
    "print(f\"Creating model with:\")\n",
    "print(f\"vocab_size: {vocab_size}\")\n",
    "print(f\"tagset_size: {tagset_size}\")\n",
    "print(f\"pad_idx: {pad_idx}\")\n",
    "\n",
    "# Tạo trên CPU trước\n",
    "model = BiLSTM_CRF(vocab_size, tagset_size, embedding_dim, hidden_dim, pad_idx)\n",
    "print(\"Model created on CPU successfully\")\n",
    "\n",
    "try:\n",
    "    sample_x = X[:2]  # CPU\n",
    "    sample_y = y[:2]  # CPU  \n",
    "    sample_mask = mask[:2]  # CPU\n",
    "    \n",
    "    loss = model(sample_x, tags=sample_y, mask=sample_mask)\n",
    "    print(f\"CPU test successful, loss: {loss.item()}\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device.type == \"cuda\":\n",
    "        model = model.to(device)\n",
    "        print(\"Model moved to GPU successfully\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    print(\"Setup complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Problem is in BiLSTM_CRF class or data, not CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0/1274, Loss: 62.5754\n",
      "Epoch 1, Step 200/1274, Loss: 7.7107\n",
      "Epoch 1, Step 400/1274, Loss: 6.9028\n",
      "Epoch 1, Step 600/1274, Loss: 8.3703\n",
      "Epoch 1, Step 800/1274, Loss: 3.7171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [126,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [125,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m optimizer.zero_grad()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#Backward\u001b[39;00m\n\u001b[32m     16\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mBiLSTM_CRF.forward\u001b[39m\u001b[34m(self, x, tags, mask)\u001b[39m\n\u001b[32m     18\u001b[39m emissions = \u001b[38;5;28mself\u001b[39m.fc(lstm_out)               \u001b[38;5;66;03m# [batch, seq_len, tagset_size]\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Training -> trả loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     loss = -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Inference -> decode best path\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchcrf/__init__.py:90\u001b[39m, in \u001b[36mCRF.forward\u001b[39m\u001b[34m(self, emissions, tags, mask, reduction)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     65\u001b[39m         emissions: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m         reduction: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     69\u001b[39m ) -> torch.Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the conditional log likelihood of a sequence of tags given emission scores.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m        reduction is ``none``, ``()`` otherwise.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43memissions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtoken_mean\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     92\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33minvalid reduction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreduction\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torchcrf/__init__.py:169\u001b[39m, in \u001b[36mCRF._validate\u001b[39m\u001b[34m(self, emissions, tags, mask)\u001b[39m\n\u001b[32m    167\u001b[39m no_empty_seq = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m mask[\u001b[32m0\u001b[39m].all()\n\u001b[32m    168\u001b[39m no_empty_seq_bf = \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m mask[:, \u001b[32m0\u001b[39m].all()\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_empty_seq \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_empty_seq_bf:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mmask of the first timestep must all be on\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for i, (X_batch, y_batch, mask_batch) in enumerate(train_loader):\n",
    "        # Transfer train and test data to GPU/CPU\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        mask_batch = mask_batch.to(device)\n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Forward\n",
    "        loss = model(X_batch, tags=y_batch, mask=mask_batch)\n",
    "        #Backward\n",
    "        loss.backward()\n",
    "        # Upgrade parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 200 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Step {i}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "            \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"✅ Epoch {epoch+1}/{EPOCHS} finished, Avg Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bf814",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_model\u001b[39m(model, dataloader, idx2tag, device):\n\u001b[32m      7\u001b[39m     model.eval()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, dataloader, idx2tag, device):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, mask_batch in dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            mask_batch = mask_batch.to(device)\n",
    "\n",
    "            # preds: list of list of tag indices\n",
    "            preds = model(X_batch, mask=mask_batch)\n",
    "\n",
    "            labels = y_batch.cpu().numpy().tolist()\n",
    "            masks = mask_batch.cpu().numpy().tolist()\n",
    "\n",
    "            # Loại bỏ PAD\n",
    "            for p, l, m in zip(preds, labels, masks):\n",
    "                true_l = [ll for ll, mm in zip(l, m) if mm == 1]\n",
    "                true_p = [pp for pp, mm in zip(p, m) if mm == 1]  # bỏ PAD trong preds\n",
    "                all_labels.extend(true_l)\n",
    "                all_preds.extend(true_p)\n",
    "\n",
    "    # Chuyển chỉ số sang nhãn\n",
    "    all_labels_str = [idx2tag[i] for i in all_labels]\n",
    "    all_preds_str = [idx2tag[i] for i in all_preds]\n",
    "\n",
    "    # Loại bỏ PAD khỏi target_names\n",
    "    labels_no_pad = [i for i, tag in idx2tag.items() if tag != \"PAD\"]\n",
    "    target_names_no_pad = [idx2tag[i] for i in labels_no_pad]\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(all_labels_str, all_preds_str,\n",
    "                                   labels=target_names_no_pad)\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(report)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels_str, all_preds_str,\n",
    "                          labels=target_names_no_pad)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d',\n",
    "                xticklabels=target_names_no_pad,\n",
    "                yticklabels=target_names_no_pad,\n",
    "                cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return all_preds_str, all_labels_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds_str, all_labels_str = evaluate_model(model, test_loader, idx2tag, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
