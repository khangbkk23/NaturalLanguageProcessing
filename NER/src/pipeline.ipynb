{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6db3c95",
   "metadata": {},
   "source": [
    "# Implement the pipeline for Named Entity Recognition with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee164d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was last compiled at: 2025-09-05 20:48:02\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"This notebook was last compiled at: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab375dd1",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_dir, mode=None):\n",
    "    df = pd.read_csv(data_dir, encoding=\"ISO-8859-1\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca0b53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "    Sentence #           Word  POS    Tag\n",
      "0  Sentence: 1      Thousands  NNS      O\n",
      "1          NaN             of   IN      O\n",
      "2          NaN  demonstrators  NNS      O\n",
      "3          NaN           have  VBP      O\n",
      "4          NaN        marched  VBN      O\n",
      "5          NaN        through   IN      O\n",
      "6          NaN         London  NNP  B-geo\n",
      "7          NaN             to   TO      O\n",
      "8          NaN        protest   VB      O\n",
      "9          NaN            the   DT      O\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"/mnt/e/Development/Python/NLP/NaturalLanguageProcessing/\"\n",
    "data_dir = source_dir + \"data/archive/ner_dataset.csv\"\n",
    "print(os.path.exists(data_dir))\n",
    "df = load_data(data_dir)\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a01a97",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8af9ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence #    1000616\n",
      "Word               10\n",
      "POS                 0\n",
      "Tag                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0537d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    # Fill NaN values in \"Sentence #\"\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].ffill()\n",
    "    data[\"Sentence #\"] = data[\"Sentence #\"].astype(str)\n",
    "\n",
    "    # Drop rows with missing Word\n",
    "    data = data.dropna(subset=[\"Word\"]).reset_index(drop=True)\n",
    "\n",
    "    # Strip whitespace\n",
    "    for col in [\"Word\", \"POS\", \"Tag\"]:\n",
    "        data[col] = data[col].str.strip()\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb6ab55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = preprocessing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fe79240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')], [('Iranian', 'B-gpe'), ('officials', 'O'), ('say', 'O'), ('they', 'O'), ('expect', 'O'), ('to', 'O'), ('get', 'O'), ('access', 'O'), ('to', 'O'), ('sealed', 'O'), ('sensitive', 'O'), ('parts', 'O'), ('of', 'O'), ('the', 'O'), ('plant', 'O'), ('Wednesday', 'B-tim'), (',', 'O'), ('after', 'O'), ('an', 'O'), ('IAEA', 'B-org'), ('surveillance', 'O'), ('system', 'O'), ('begins', 'O'), ('functioning', 'O'), ('.', 'O')], [('Helicopter', 'O'), ('gunships', 'O'), ('Saturday', 'B-tim'), ('pounded', 'O'), ('militant', 'O'), ('hideouts', 'O'), ('in', 'O'), ('the', 'O'), ('Orakzai', 'B-geo'), ('tribal', 'O'), ('region', 'O'), (',', 'O'), ('where', 'O'), ('many', 'O'), ('Taliban', 'B-org'), ('militants', 'O'), ('are', 'O'), ('believed', 'O'), ('to', 'O'), ('have', 'O'), ('fled', 'O'), ('to', 'O'), ('avoid', 'O'), ('an', 'O'), ('earlier', 'O'), ('military', 'O'), ('offensive', 'O'), ('in', 'O'), ('nearby', 'O'), ('South', 'B-geo'), ('Waziristan', 'I-geo'), ('.', 'O')], [('They', 'O'), ('left', 'O'), ('after', 'O'), ('a', 'O'), ('tense', 'O'), ('hour-long', 'O'), ('standoff', 'O'), ('with', 'O'), ('riot', 'O'), ('police', 'O'), ('.', 'O')], [('U.N.', 'B-geo'), ('relief', 'O'), ('coordinator', 'O'), ('Jan', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('Sunday', 'B-tim'), (',', 'O'), ('U.S.', 'B-geo'), (',', 'O'), ('Indonesian', 'B-gpe'), ('and', 'O'), ('Australian', 'B-gpe'), ('military', 'O'), ('helicopters', 'O'), ('are', 'O'), ('ferrying', 'O'), ('out', 'O'), ('food', 'O'), ('and', 'O'), ('supplies', 'O'), ('to', 'O'), ('remote', 'O'), ('areas', 'O'), ('of', 'O'), ('western', 'O'), ('Aceh', 'B-geo'), ('province', 'O'), ('that', 'O'), ('ground', 'O'), ('crews', 'O'), ('can', 'O'), ('not', 'O'), ('reach', 'O'), ('.', 'O')], [('Mr.', 'B-per'), ('Egeland', 'I-per'), ('said', 'O'), ('the', 'O'), ('latest', 'O'), ('figures', 'O'), ('show', 'O'), ('1.8', 'O'), ('million', 'O'), ('people', 'O'), ('are', 'O'), ('in', 'O'), ('need', 'O'), ('of', 'O'), ('food', 'O'), ('assistance', 'O'), ('-', 'O'), ('with', 'O'), ('the', 'O'), ('need', 'O'), ('greatest', 'O'), ('in', 'O'), ('Indonesia', 'B-tim'), (',', 'O'), ('Sri', 'B-per'), ('Lanka', 'B-gpe'), (',', 'O'), ('the', 'O'), ('Maldives', 'B-geo'), ('and', 'O'), ('India', 'B-geo'), ('.', 'O')], [('He', 'O'), ('said', 'O'), ('last', 'O'), ('week', 'O'), (\"'s\", 'O'), ('tsunami', 'O'), ('and', 'O'), ('the', 'O'), ('massive', 'O'), ('underwater', 'O'), ('earthquake', 'O'), ('that', 'O'), ('triggered', 'O'), ('it', 'O'), ('has', 'O'), ('affected', 'O'), ('millions', 'O'), ('in', 'O'), ('Asia', 'B-geo'), ('and', 'O'), ('Africa', 'B-geo'), ('.', 'O')], [('Some', 'O'), ('1,27,000', 'O'), ('people', 'O'), ('are', 'O'), ('known', 'O'), ('dead', 'O'), ('.', 'O')], [('Aid', 'O'), ('is', 'O'), ('being', 'O'), ('rushed', 'O'), ('to', 'O'), ('the', 'O'), ('region', 'O'), (',', 'O'), ('but', 'O'), ('the', 'O'), ('U.N.', 'B-geo'), ('official', 'O'), ('stressed', 'O'), ('that', 'O'), ('bottlenecks', 'O'), ('and', 'O'), ('a', 'O'), ('lack', 'O'), ('of', 'O'), ('infrastructure', 'O'), ('remain', 'O'), ('a', 'O'), ('challenge', 'O'), ('.', 'O')], [('Lebanese', 'B-gpe'), ('politicians', 'O'), ('are', 'O'), ('condemning', 'O'), ('Friday', 'B-tim'), (\"'s\", 'O'), ('bomb', 'O'), ('blast', 'O'), ('in', 'O'), ('a', 'O'), ('Christian', 'O'), ('neighborhood', 'O'), ('of', 'O'), ('Beirut', 'B-geo'), ('as', 'O'), ('an', 'O'), ('attempt', 'O'), ('to', 'O'), ('sow', 'O'), ('sectarian', 'O'), ('strife', 'O'), ('in', 'O'), ('the', 'O'), ('formerly', 'O'), ('war-torn', 'O'), ('country', 'O'), ('.', 'O')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2568/755275269.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df.groupby(\"Sentence #\").apply(\n"
     ]
    }
   ],
   "source": [
    "# Groupby follow sentence for training\n",
    "grouped = df.groupby(\"Sentence #\").apply(\n",
    "    lambda s: list(zip(s[\"Word\"], s[\"Tag\"]))\n",
    ").tolist()\n",
    "\n",
    "print(grouped[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba12d33",
   "metadata": {},
   "source": [
    "## Encoding data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
