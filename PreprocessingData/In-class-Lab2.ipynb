{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1scE5rBNAR2G"
   },
   "source": [
    "# In-class Lab 2: Text Data Preprocessing\n",
    "**Overview:** In this lesson, we will build a text preprocessing pipeline for English text, which includes: data cleaning, converting to lowercase, removing punctuation, tokenization, removing stop words, and stemming. The exercise requires knowledge and programming skills in Python using libraries such as string, re, nltk, and numpy.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G8XZPuMAR2T"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "8ijK-PShAR2V"
   },
   "outputs": [],
   "source": [
    "import string # used for preprocessing\n",
    "import re # used for preprocessing\n",
    "import nltk # the Natural Language Toolkit, used for preprocessing\n",
    "import numpy as np # used for managing NaNs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords # used for preprocessing\n",
    "from nltk.stem import WordNetLemmatizer # used for preprocessing\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0DQgAkWAR2W"
   },
   "source": [
    "## Question 1: Exploring the Dataset\n",
    "\n",
    "The raw text data that needs preprocessing is in the file \"wiki.txt\". This file contains short documents (docs), with each document on a separate line. In this question, we will explore the following:\n",
    "\n",
    "- The number of docs in the corpus\n",
    "- Observing a few docs from the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "GsbV9GSEAR2X",
    "outputId": "e5590b0b-38c0-4f34-bd1b-b202ded3338d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 2362\n",
      "Document 1: Madhuca utilis is a tree in the Sapotaceae family. It grows up to 40 metres (130 ft) tall, with a trunk diameter of up to 70 centimetres (28 in). The bark is greyish brown. The fruits are ellipsoid, up to 5.5 centimetres (2.2 in) long. The specific epithet utilis is from the Latin meaning \\\"useful\\\", referring to the timber. Habitat is swamps and lowland kerangas forests. M. utilis is found in Sumatra, Peninsular Malaysia and Borneo.\n",
      "\n",
      "Document 2: The Lycée Edmond Perrier (Edmond Perrier high school) is a general and technical secondary education institution, located in Tulle, Correze. It is dedicated to zoologist Edmond Perrier, born in Tulle in 1844. It was built by Anatole de Baudot, and has many similarities with the Lycée Lakanal, due to the same architect. His motto is \\\"Sint rupes virtutis iter\\\", identical to that of Tulle which means \\\"The difficulties are the path of virtue\\\".\n",
      "\n",
      "Document 3: Shareh Khvor (Persian: شره خور‎‎) is a village in Bask-e Kuleseh Rural District, in the Central District of Sardasht County, West Azerbaijan Province, Iran. At the 2006 census, its population was 14, in 4 families.\n",
      "\n",
      "Document 4: St. Rose Roman Catholic Church Complex is a Roman Catholic church complex located at Lima in Livingston County, New York. The complex consists of four contributing buildings: 1) St. Rose Church, constructed 1870-1873; 2) Brendan Hall, constructed in 1894 as a parochial school; 3) rectory; and 4) convent. It was listed on the National Register of Historic Places in 1988.\n",
      "\n",
      "Document 5: Langangen is a village in Porsgrunn municipality, Telemark county, in Norway. Langangen borders to Larvik municipality and Vestfold county. Its population is 499 (2009 Census). Langangen was earlier divided by European route E18 but in 1979 the road was led over Langangen bridge. Langangen has its own elementary school and chapel.\n",
      "\n",
      "Document 6: José Enrique Moyal (1 October 1910 – 22 May 1998) was a mathematical physicist who contributed to aeronautical engineering, electrical engineering and statistics, among other fields. He helped establish the phase space formulation of quantum mechanics in 1949 by bringing together the ideas of Hermann Weyl, John von Neumann, Eugene Wigner, and Hip Groenewold.This formulation is statistical in nature and makes logical connections between quantum mechanics and classical statistical mechanics, enabling a natural comparison between the two formulations. \\\"Phase Space Quantization,\\\" is a synonym for \\\"Moyal Quantization\\\" and largely avoids use of operators for quantum mechanical observables prevalent in the canonical formulation.Quantum-mechanical evolution in phase space is specified by a Moyal bracket. Moyal grew up in Tel Aviv, and attended the Herzliya Hebrew Gymnasium. He studied in Paris in the 1930s, at the École Supérieure d'Electricité, Institut de Statistique, and, finally, at the Institut Henri Poincaré. His work was carried out in wartime England in the 1940s, while employed at the de Havilland Aircraft company. He was a professor of mathematics at Macquarie University, a colleague of John Clive Ward at the former School of Mathematics and Physics, having previously worked at Argonne National Laboratory in Illinois.\n",
      "\n",
      "Document 7: George Montagu (1753 – 20 June 1815) was an English army officer and naturalist. He was known for his pioneering Ornithological Dictionary of 1802, which for the first time accurately defined the status of Britain's birds. He is remembered today for species such as the Montagu's harrier, named for him.\n",
      "\n",
      "Document 8: The Chestertown Armory is a historic National Guard armory built in 1931 and located in Chestertown, Kent County, Maryland, United States. It is a two-story brick structure with a full basement that emulates a medieval fortification. The front facade features an entryway flanked by simple two-story towers, which are topped by small square stone panels. The Armory hall is used for dances and cotillions, local hospital benefits, and other social functions, and the Friends of the Library hold annual trade shows there. The Chestertown Armory was listed on the National Register of Historic Places in 1985.\n",
      "\n",
      "Document 9: Spiczyn [ˈspit͡ʂɨn] is a village in Łęczna County, Lublin Voivodeship, in eastern Poland and is the seat of the gmina (administrative district) called Gmina Spiczyn. It lies approximately 10 kilometres (6 mi) north-west of Łęczna and 18 km (11 mi) north-east of the regional capital Lublin.\n",
      "\n",
      "Document 10: Trash is the first full-length album by Japanese hardcore punk group The Stalin released on December 24, 1981. Full album released from political records that is independent music label for the first time as The Stalin. At that time, 2000 pieces were newly pressed because it sold all immediately after release, and the order poured in, and sales of the exception were recorded in the independent music label though as many as 1000 pieces were pressed at first because it was an independent production board. However, all re-release is not done, and a still hard-to-find work according to the problem in extreme content and contract of the use of the broadcasting prohibition term. A lot of bootlegs appear on the market, too and therefore, the CD board is only a bootleg and exists. A-side are studio recording sound source and B-side are a live sound sources. The content of the album Several of collection changes the title in the work after the following majors debut, and what it tried to record is collected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "with open(\"wiki.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text_lst = [line.strip() for line in file if line.strip()]\n",
    "    \n",
    "print(f\"Number of docs: {len(text_lst)}\")\n",
    "\n",
    "# Try to print a few docs from the corpus\n",
    "for i, doc in enumerate(text_lst[:10], start = 1):\n",
    "    print(f\"Document {i}: {doc}\\n\")\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Building Text Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6I8R30NAR2c"
   },
   "source": [
    "### Question 2.1: Building a Data Cleaning Function\n",
    "\n",
    "**Description:** The function removes digits and keeps only the characters \"A-Za-z(),!?\\'\\`\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "80LZzOxCAR2d"
   },
   "outputs": [],
   "source": [
    "# clean text\n",
    "def clean_text(text):\n",
    "    #### YOUR CODE HERE ####\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    cleaned_text = re.sub(r\"[^A-Za-z(),!?\\'\\`\\s]\", \"\", text)\n",
    "    return cleaned_text\n",
    "    #### END YOUR CODE #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLyDqwtcAR2d"
   },
   "source": [
    "### Question 2.2: Function to Convert Text to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "v5N6q83DAR2e"
   },
   "outputs": [],
   "source": [
    "# make all text lowercase\n",
    "#### YOUR CODE HERE ####\n",
    "def text_lowercase(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    return text.lower()\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vkzajg44AR2e"
   },
   "source": [
    "### Question 2.3: Building a Function to Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "lLFWvQRLAR2f"
   },
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    #### YOUR CODE HERE ####\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove all punctuation characters\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_ocSyA9AR2f"
   },
   "source": [
    "### Question 2.4: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "ru8lNWuDAR2g"
   },
   "outputs": [],
   "source": [
    "# tokenize\n",
    "def tokenize(text):\n",
    "    #### YOUR CODE HERE ####    \n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    return word_tokenize(text)\n",
    "    #### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9L8rJildAR2g"
   },
   "source": [
    "### Question 2.5: Removing Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-03fXud4AR2h"
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#### YOUR CODE HERE ####\n",
    "def remove_stopwords(text):\n",
    "    if text is None:\n",
    "        return []\n",
    "    return [token for token in text if token not in stop_words]\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVXH3PorAR2h"
   },
   "source": [
    "### Question 2.6: Building a Lemmatization Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "hNb3hemPAR2i"
   },
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#### YOUR CODE HERE ####\n",
    "def lemmatize(text):\n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    return [lemmatizer.lemmatize(token.lower()) for token in text]\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pr3h3J4AR2i"
   },
   "source": [
    "### Question 2.7: Building a Preprocessing Function\n",
    "**Hint:** This function will call the functions written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "lpM1j8v9AR2i"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocessing(text):\n",
    "#### YOUR CODE HERE ####\n",
    "    # Check if text is available\n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    # Clean text\n",
    "    cleaned = clean_text(text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    lowercased = text_lowercase(cleaned)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    punct_removed = remove_punctuation(lowercased)\n",
    "    \n",
    "    # Tokenizing text\n",
    "    tokenized = tokenize(punct_removed)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stopwords_removed = remove_stopwords(tokenized)\n",
    "    \n",
    "    # Lemmatizing text\n",
    "    lemmatized = lemmatize(stopwords_removed)\n",
    "    \n",
    "    final_tokens = [token for token in lemmatized if token.strip()]\n",
    "    return final_tokens\n",
    "#### END YOUR CODE #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQJicZUrAR2j"
   },
   "source": [
    "## Question 3: Preprocessing for Input Text\n",
    "**Overview:** Using the functions above, preprocess the initial text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "tSWwb3gsAR2j",
    "outputId": "5e0d91f7-f4cb-4998-e890-c38bb064377b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: ['madhuca', 'utilis', 'tree', 'sapotaceae', 'family', 'grows', 'metre', 'ft', 'tall', 'trunk', 'diameter', 'centimetre', 'bark', 'greyish', 'brown', 'fruit', 'ellipsoid', 'centimetre', 'long', 'specific', 'epithet', 'utilis', 'latin', 'meaning', 'useful', 'referring', 'timber', 'habitat', 'swamp', 'lowland', 'kerangas', 'forest', 'utilis', 'found', 'sumatra', 'peninsular', 'malaysia', 'borneo']\n",
      "Document 2: ['lyce', 'edmond', 'perrier', 'edmond', 'perrier', 'high', 'school', 'general', 'technical', 'secondary', 'education', 'institution', 'located', 'tulle', 'correze', 'dedicated', 'zoologist', 'edmond', 'perrier', 'born', 'tulle', 'built', 'anatole', 'de', 'baudot', 'many', 'similarity', 'lyce', 'lakanal', 'due', 'architect', 'motto', 'sint', 'rupes', 'virtutis', 'iter', 'identical', 'tulle', 'mean', 'difficulty', 'path', 'virtue']\n",
      "Document 3: ['shareh', 'khvor', 'persian', 'village', 'baske', 'kuleseh', 'rural', 'district', 'central', 'district', 'sardasht', 'county', 'west', 'azerbaijan', 'province', 'iran', 'census', 'population', 'family']\n",
      "Document 4: ['st', 'rose', 'roman', 'catholic', 'church', 'complex', 'roman', 'catholic', 'church', 'complex', 'located', 'lima', 'livingston', 'county', 'new', 'york', 'complex', 'consists', 'four', 'contributing', 'building', 'st', 'rose', 'church', 'constructed', 'brendan', 'hall', 'constructed', 'parochial', 'school', 'rectory', 'convent', 'listed', 'national', 'register', 'historic', 'place']\n",
      "Document 5: ['langangen', 'village', 'porsgrunn', 'municipality', 'telemark', 'county', 'norway', 'langangen', 'border', 'larvik', 'municipality', 'vestfold', 'county', 'population', 'census', 'langangen', 'earlier', 'divided', 'european', 'route', 'e', 'road', 'led', 'langangen', 'bridge', 'langangen', 'elementary', 'school', 'chapel']\n",
      "Document 6: ['jos', 'enrique', 'moyal', 'october', 'may', 'mathematical', 'physicist', 'contributed', 'aeronautical', 'engineering', 'electrical', 'engineering', 'statistic', 'among', 'field', 'helped', 'establish', 'phase', 'space', 'formulation', 'quantum', 'mechanic', 'bringing', 'together', 'idea', 'hermann', 'weyl', 'john', 'von', 'neumann', 'eugene', 'wigner', 'hip', 'groenewoldthis', 'formulation', 'statistical', 'nature', 'make', 'logical', 'connection', 'quantum', 'mechanic', 'classical', 'statistical', 'mechanic', 'enabling', 'natural', 'comparison', 'two', 'formulation', 'phase', 'space', 'quantization', 'synonym', 'moyal', 'quantization', 'largely', 'avoids', 'use', 'operator', 'quantum', 'mechanical', 'observables', 'prevalent', 'canonical', 'formulationquantummechanical', 'evolution', 'phase', 'space', 'specified', 'moyal', 'bracket', 'moyal', 'grew', 'tel', 'aviv', 'attended', 'herzliya', 'hebrew', 'gymnasium', 'studied', 'paris', 'cole', 'suprieure', 'delectricit', 'institut', 'de', 'statistique', 'finally', 'institut', 'henri', 'poincar', 'work', 'carried', 'wartime', 'england', 'employed', 'de', 'havilland', 'aircraft', 'company', 'professor', 'mathematics', 'macquarie', 'university', 'colleague', 'john', 'clive', 'ward', 'former', 'school', 'mathematics', 'physic', 'previously', 'worked', 'argonne', 'national', 'laboratory', 'illinois']\n",
      "Document 7: ['george', 'montagu', 'june', 'english', 'army', 'officer', 'naturalist', 'known', 'pioneering', 'ornithological', 'dictionary', 'first', 'time', 'accurately', 'defined', 'status', 'britain', 'bird', 'remembered', 'today', 'specie', 'montagu', 'harrier', 'named']\n",
      "Document 8: ['chestertown', 'armory', 'historic', 'national', 'guard', 'armory', 'built', 'located', 'chestertown', 'kent', 'county', 'maryland', 'united', 'state', 'twostory', 'brick', 'structure', 'full', 'basement', 'emulates', 'medieval', 'fortification', 'front', 'facade', 'feature', 'entryway', 'flanked', 'simple', 'twostory', 'tower', 'topped', 'small', 'square', 'stone', 'panel', 'armory', 'hall', 'used', 'dance', 'cotillion', 'local', 'hospital', 'benefit', 'social', 'function', 'friend', 'library', 'hold', 'annual', 'trade', 'show', 'chestertown', 'armory', 'listed', 'national', 'register', 'historic', 'place']\n",
      "Document 9: ['spiczyn', 'spitn', 'village', 'czna', 'county', 'lublin', 'voivodeship', 'eastern', 'poland', 'seat', 'gmina', 'administrative', 'district', 'called', 'gmina', 'spiczyn', 'lie', 'approximately', 'kilometre', 'mi', 'northwest', 'czna', 'km', 'mi', 'northeast', 'regional', 'capital', 'lublin']\n",
      "Document 10: ['trash', 'first', 'fulllength', 'album', 'japanese', 'hardcore', 'punk', 'group', 'stalin', 'released', 'december', 'full', 'album', 'released', 'political', 'record', 'independent', 'music', 'label', 'first', 'time', 'stalin', 'time', 'piece', 'newly', 'pressed', 'sold', 'immediately', 'release', 'order', 'poured', 'sale', 'exception', 'recorded', 'independent', 'music', 'label', 'though', 'many', 'piece', 'pressed', 'first', 'independent', 'production', 'board', 'however', 'rerelease', 'done', 'still', 'hardtofind', 'work', 'according', 'problem', 'extreme', 'content', 'contract', 'use', 'broadcasting', 'prohibition', 'term', 'lot', 'bootleg', 'appear', 'market', 'therefore', 'cd', 'board', 'bootleg', 'exists', 'aside', 'studio', 'recording', 'sound', 'source', 'bside', 'live', 'sound', 'source', 'content', 'album', 'several', 'collection', 'change', 'title', 'work', 'following', 'major', 'debut', 'tried', 'record', 'collected']\n"
     ]
    }
   ],
   "source": [
    "#### YOUR CODE HERE ####\n",
    "processed_corpus = []\n",
    "\n",
    "for text in text_lst:\n",
    "    tokens = preprocessing(text)\n",
    "    processed_corpus.append(tokens)\n",
    "\n",
    "for i, doc in enumerate(processed_corpus[:10], 1):\n",
    "    print(f\"Document {i}: {doc}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
